---
id: "0009"
title: Personalisation / Concierge Service Architecture
status: proposed
date: 2025-10-18
---

## Context and Problem Statement

MobilityCorp intends to offer a **personalised “Concierge” experience** to enhance customer engagement and retention.  
This service will recommend vehicles, preferred routes, or hubs based on each user’s historical behaviour and contextual signals (time, weather, events, typical destinations).

The service must:
- Be **strictly opt-in** under GDPR (explicit consent required).
- Maintain **complete segregation** from operational and anonymous usage data.
- Support **explainable recommendations** (why this suggestion was made).
- Allow future **monetisation as a premium tier** (personalised routing, availability guarantees, loyalty perks).

This personalisation layer sits atop the **Demand Prediction Service (ADR-0004)** and consumes forecasts, hub availability, and pricing context to offer tailored experiences.

---

## Questions

- How do we provide meaningful recommendations without violating GDPR data-minimisation principles?  
- Should personalised models run centrally or per-user segment?  
- How do we manage consent revocation and data erasure consistently across systems?  
- Can personalisation operate in *shadow mode* (collect feedback before launch)?  
- How do we explain recommendations in plain language for transparency?

---

## Options

### Option A — No Personalisation (Anonymous Only)
Operate purely on aggregate demand; no user profiling.

**Pros**
- Simplest and safest for GDPR.  
- No PII processing risk.

**Cons**
- Lower engagement; missed premium upsell opportunity.  

---

### Option B — Shared Model with User Embeddings
Train shared models (e.g., matrix factorisation, gradient-boosted trees with user embeddings) using pseudonymised IDs.

**Pros**
- Compact, performant, explainable with SHAP/feature attribution.  
- Good balance of accuracy and privacy.  

**Cons**
- Must rigorously enforce opt-in filtering.  
- Harder to delete individual embeddings on withdrawal.  

---

### Option C — Per-User Models (On-Demand Training)
Train lightweight per-user models on device or ephemeral cloud jobs.

**Pros**
- Maximum privacy and control (no cross-user contamination).  
- Clear data-deletion semantics.

**Cons**
- High compute cost at scale.  
- Limited ability to leverage population-level patterns.

---

### Option D — Hybrid Architecture (**Recommended**)
Implement a **segregated Personalisation Store** that hosts **user-level profiles** only for opt-in customers.  
Use a **shared model backbone** (trained on anonymised population data) to generate feature embeddings;  
then run **personalised scoring or re-ranking** per user using their consented history.

**Pros**
- Balances performance and privacy.  
- Easy to enable/disable via consent flags.  
- Supports premium-tier monetisation.  
- Compatible with Forecasting (ADR-0004) and Routing (ADR-0005).  
- Enables explainability and user transparency.

**Cons**
- Requires dual-path data governance (anonymous + personalised).  
- Slightly more complex ML orchestration and access controls.

---

## Decision

Adopt **Option D – Hybrid Personalisation Architecture**.

- A **Personalisation Service** provides personalised recommendations via API (e.g., `/recommend/hub`, `/recommend/route`, `/recommend/vehicle`).  
- It consumes anonymised global forecasts from **Demand Prediction (ADR-0004)** and contextual data (weather, time, events) from the **Data Platform (ADR-0007)**.  
- It reads **opt-in user profiles** from a **segregated Personalisation Store**, physically and logically isolated from the core operational database.  
- All personalisation computations run in the **EU region** and are governed by **AI Interchange (ADR-0016)** for explainability, audit, and cost tracking.  
- The service can be gated behind a **premium subscription** in future releases.

---

## Consequences

**Positive**
- Creates differentiated, premium experience compliant with GDPR.  
- Enhances engagement and retention through tailored suggestions.  
- Clear separation of PII and anonymous operational data.  
- Enables explainable recommendations (via SHAP, counterfactuals).  

**Trade-offs**
- Additional governance and operational complexity.  
- Limited dataset size (only opt-in users).  
- Requires consent management and periodic data purges.  

---

## Implementation Details (High-level)

| Component | Responsibility | Notes |
|------------|----------------|-------|
| **Personalisation Service** | Serves `/recommend/*` APIs; merges global predictions with user history | Deploy as independent microservice |
| **Personalisation Store** | Segregated datastore for opt-in user history & embeddings | EU-resident; encrypted; consent-flag index |
| **Consent Manager** | Handles opt-in/out, DSR requests, data erasure | Federated with GDPR system |
| **Model Training Pipeline** | Trains population-level models; fine-tunes personalised re-rankers | Uses AI Interchange (ADR-0016) |
| **Explainability Engine** | Generates human-readable explanations (“because you usually rent scooters near Hub-5 on weekends”) | Required under EU AI Act |
| **Audit Log (ADR-0013)** | Logs consent state, inference events, explanations | Immutable, time-stamped |
| **API Gateway** | Routes requests; enforces JWT scopes (premium tier, consent required) | Integration with IAM |

---

### Data Flow & Privacy Controls

| Step | Description | GDPR Handling |
|------|--------------|----------------|
| **1. Consent registration** | User opts in (explicit checkbox, timestamped) | Stored in Consent Manager; tokenised user ID created |
| **2. Event collection** | User activity (rents, routes) streamed to Personalisation Store | Only if consent flag true |
| **3. Model training** | Train shared + personalised models | Pseudonymised; PII excluded |
| **4. Inference** | `/recommend` endpoint called | Tokenised ID; encrypted in transit |
| **5. Explanation + audit** | Result + rationale logged | Linked via pseudonymised ID |
| **6. Revocation** | User opts out; data purged asynchronously | Data subject deletion propagated across storage layers |

---

## Mermaid Diagram — Personalisation Flow

```mermaid
flowchart LR
    subgraph Inputs
        HIST[User Activity (opt-in)]
        FORE[Demand Forecasts\n(ADR-0004)]
        CONTX[Context Data\n(Weather, Events)]
    end

    subgraph Personalisation
        STORE[Personalisation Store\n(Segregated, EU)]
        TRAIN[Model Training Pipeline\n(Global + User Fine-tune)]
        INF[Inference Service\n(/recommend APIs)]
        EXPL[Explainability Engine]
    end

    subgraph Controls
        CONS[Consent Manager]
        AUD[Audit Log (ADR-0013)]
        AIINT[AI Interchange (ADR-0016)]
    end

    subgraph Consumers
        APP[User App]
        BO[Back Office Dashboard]
    end

    HIST --> STORE
    FORE --> TRAIN
    CONTX --> TRAIN
    STORE --> TRAIN
    TRAIN --> INF
    INF --> EXPL
    INF --> APP
    EXPL --> APP
    INF --> AUD
    CONS --> STORE
    CONS --> INF
    INF --> AIINT
    AUD --> BO

---

## Risks and Mitigations

| Risk                                             | Likelihood | Impact | Mitigation                                            |
| ------------------------------------------------ | ---------- | ------ | ----------------------------------------------------- |
| Consent mismanagement                            | Low        | High   | Dedicated Consent Manager + DSR automation            |
| Data leakage between personal & anonymous stores | Low        | High   | Network segmentation; separate encryption keys        |
| Model bias or over-personalisation               | Med        | Med    | Fairness audits, diversity thresholds                 |
| Opt-in pool too small for training               | Med        | Med    | Use global model backbone + transfer learning         |
| High compute cost for fine-tuning                | Med        | Med    | Batch training; cost guardrails (ADR-0020)            |
| Explainability gaps                              | Low        | High   | SHAP/feature attribution stored per recommendation    |
| User mistrust (“creepy factor”)                  | Med        | Med    | Clear UX: opt-in, transparent rationale, easy opt-out |

---

## Alternatives Considered

* Centralised user modelling (no consent segmentation) — rejected; GDPR risk.
* Client-side inference only — deferred; may be added for privacy-enhanced mode later.
* Third-party recommendation SaaS — rejected; data residency and control concerns.

## Links

* ADR-004 – Demand Prediction Model Design
* ADR-007 – Data Platform Architecture
* ADR-013 – Immutable Audit Log Architecture
* ADR-016 – AI Interchange Layer
* ADR-019 – AI Governance & Explainability
* ADR-020 – AI Cost & Budget Guardrails