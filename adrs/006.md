---
id: "0006"
title: Alerts & Theft Detection Logic
status: proposed
date: 2025-10-18
---

## Context and Problem Statement

MobilityCorp’s new platform must detect **potential theft, tampering, or misuse** of its shared vehicles  
(e-bikes, e-scooters, e-cars, e-vans) in real time, using signals from the external IoT telemetry provider.

The existing operational challenge is balancing **speed and accuracy**:
- False positives waste field-operative time and damage customer trust.
- False negatives increase fleet loss and insurance exposure.
- Telemetry data is inherently noisy (GPS drift, motion spikes, sensor desync).

The detection subsystem must therefore:
- Fuse multiple IoT signals (GPS, motion, lock state, tilt, battery).
- Provide **high-confidence alerts** with minimal false alarms.
- Integrate with **Field-Ops** for human verification and **Back Office** dashboards for audit.
- Maintain **GDPR compliance** and full **explainability** under the EU AI Act.

---

## Questions

- Should detection rely entirely on IoT vendor alerts or build internal intelligence?
- How can multiple weak signals be combined into a high-confidence event?
- Where does AI add value without removing human oversight?
- What are acceptable latency and false-positive thresholds?
- How are alerts prioritised, audited, and fed back for continuous improvement?

---

## Options

### Option A — Vendor-only alerts
Use IoT provider’s native movement/tamper notifications.

**Pros**
- Zero internal compute cost.
- Simplified integration.

**Cons**
- Limited configurability and transparency.
- No correlation with operational context (e.g., scheduled relocations).
- Vendor lock-in and uncertain latency.

---

### Option B — Internal Multi-Signal Rules Engine
Consume raw telemetry and evaluate deterministic conditions (e.g., motion while locked).

**Pros**
- Transparent, tunable, GDPR-safe.
- Fast inference; deterministic.

**Cons**
- Cannot adapt to subtle or emergent patterns.
- Requires ongoing manual tuning.

---

### Option C — Hybrid Vendor + Rules Correlation
Ingest vendor alerts as one input into internal rules logic.

**Pros**
- Redundant and cross-validated.
- Low lift if vendor feed is reliable.

**Cons**
- Two systems to maintain; unclear source of truth.

---

### Option D — **AI-Assisted Multi-Signal Detection (Hybrid Model)**
Combine deterministic rules with an AI model that scores the **probability of theft or misuse**.  
The model analyses patterns across GPS displacement, motion vectors, tilt, battery drop rate, and lock-state transitions to output an anomaly score (0–1).  
The **Alert Fusion layer** merges rule triggers and AI scores to prioritise alerts for human triage.

**Pros**
- Learns subtle correlations (e.g., towing, gradual drift, complex misuse).
- Reduces false positives and alert fatigue.
- Uses MobilityCorp’s historical telemetry and verified theft records for training.
- Enables continuous improvement through feedback loops.

**Cons**
- Adds ML lifecycle management (training, retraining, monitoring).
- Requires explainability tooling (SHAP/LIME).
- Needs fairness and bias auditing for regulatory compliance.

---

## Decision

Adopt **Option D – AI-assisted hybrid detection** as the foundation of the new platform.

- **Rules Engine** remains authoritative for deterministic triggers.
- **AI Model** provides anomaly scoring and alert prioritisation.
- **Alert Fusion Layer** combines both signals into a unified alert stream.
- Models are hosted and governed through the **AI Interchange Layer (ADR-016)**.
- Every alert includes both the triggering rule(s) and AI confidence score for auditability.
- The system retains a **human-in-loop verification** step; AI never autonomously closes cases.

---

## Consequences

**Positive**
- Substantial reduction in false positives and wasted dispatches.  
- Continuous self-learning using verified outcomes.  
- Strong compliance posture with full traceability and explainability.  
- Shared AI infrastructure and cost tracking (ADR-020).

**Trade-offs**
- Increased architecture complexity and monitoring overhead.  
- Requires retraining pipelines and feature governance.  
- Must enforce fairness and bias detection in production.

---

## Implementation Details (High-Level)

| Component | Function | Notes |
|------------|-----------|-------|
| **IoT Platform (external)** | Emits raw telemetry (GPS, motion, tilt, lock, battery). | Source of truth. |
| **Telemetry Ingestion** | Normalises and validates telemetry stream. | Kafka / stream processor. |
| **Rules Engine** | Applies deterministic conditions (e.g., motion + locked). | Fast path; mandatory triggers. |
| **AI Model** | Predicts anomaly score (0–1). | Gradient boosting or autoencoder; trained on historical data. |
| **Alert Fusion Layer** | Merges rule results + AI score; ranks alerts. | Weighted ensemble with thresholds. |
| **Alert Queue** | Streams confirmed alerts for consumption. | Kafka topic / event bus. |
| **Field-Ops App** | Receives alert tasks for in-person verification. | Mobile interface. |
| **Back Office Dashboard** | Visualises alerts, confidence, status, SLA metrics. | Web UI. |
| **Audit Log (ADR-013)** | Stores immutable record of all alerts, scores, and outcomes. | Hash-chain ledger. |

---

## Detection Logic (Simplified Examples)

| Rule | Description | Confidence Impact |
|------|--------------|------------------|
| `unlocked && motion && !rental_active` | Movement without rental. | High |
| `gps_jump > 50 m within 10 s && lock=locked` | Possible lift or tow. | High |
| `tilt_detected && wind_speed < threshold` | Manual tamper, not weather. | Medium |
| `battery_drop_rate > 15%/min` | Possible disconnection. | Medium |
| `signal_loss > 5 min && last_state=unlocked` | Device removal / theft. | High |

---

## Risks and Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|-------------|---------|-------------|
| Model drift | Med | High | Continuous monitoring + scheduled retrain. |
| False negatives | Med | High | Keep rules authoritative; threshold tuning. |
| Bias across locations | Low–Med | Med | Fairness evaluation per region. |
| Explainability gaps | Low | High | SHAP feature attribution stored per alert. |
| AI cost spikes | Low | Med | Batch inference + budget guardrails (ADR-020). |

---

## Mermaid Sequence – Alert Lifecycle

```mermaid
sequenceDiagram
    title Alerts & Theft Detection – Hybrid Flow

    participant IOT as IoT Telemetry Platform
    participant ING as Telemetry Ingestion Layer
    participant RULES as Rules Engine
    participant AI as AI Model (Anomaly Scorer)
    participant FUSION as Alert Fusion Layer
    participant QUEUE as Alert Queue
    participant OPS as Field-Ops App
    participant BO as Back Office
    participant AUD as Audit Log

    %% Ingestion and analysis
    IOT-->>ING: Stream telemetry {GPS, motion, tilt, lock, battery}
    ING-->>RULES: Normalised events
    ING-->>AI: Feature vectors for scoring
    RULES-->>FUSION: Rule trigger results
    AI-->>FUSION: Anomaly score (0–1)
    FUSION-->>QUEUE: Emit unified alert {type, confidence, evidence}

    %% Alert handling
    QUEUE-->>OPS: Push verification task
    QUEUE-->>BO: Display alert on dashboard
    OPS-->>BO: Submit verification outcome (true/false theft)
    BO-->>AUD: Record final result + AI explanation

    %% Feedback loop
    BO-->>AI: Provide labelled data for retraining pipeline
