---
id: "0008"
title: Mobile Offline Sync Strategy
status: proposed
date: 2025-10-18
---

## Context and Problem Statement

Field Operatives at MobilityCorp frequently operate in areas with **weak or intermittent connectivity** —  
underground parking structures, suburban zones, or remote service areas.

To maintain operational continuity and data integrity, the **Field-Ops App** must:

- Function seamlessly **offline** (view assigned routes, record actions, update task status).  
- **Queue updates locally** until network connectivity returns.  
- Perform **safe, deterministic synchronisation** once reconnected.  
- Resolve conflicts predictably when the same task or record is modified on multiple devices.  
- Maintain **auditability** (who did what, when) for compliance and SLA tracking.  

The goal is to guarantee **reliability and user trust** while maintaining **data integrity and explainability** for operational analytics.

---

## Questions

- Should the mobile app store a full local database or a lightweight cache?  
- What is the conflict-resolution model — **client-wins**, **server-wins**, or **merge-policy**?  
- How can we ensure **idempotency** and **audit trail continuity** across sync cycles?  
- What frameworks or storage layers best support offline-first architectures?  
- How do we handle **schema evolution** and backward compatibility for local data?  

---

## Options

### Option A — Online-Only
App requires constant connectivity; no local persistence.

**Pros**
- Simplest implementation.  
- Centralised logic; fewer sync concerns.

**Cons**
- Unusable in connectivity gaps.  
- Data loss risk; poor user experience.  

---

### Option B — Full Local Cache with Periodic Sync
Entire task/route dataset cached locally; bi-directional sync on reconnect.

**Pros**
- Robust offline experience.  
- Supports complete audit of local actions.

**Cons**
- Large local footprint; more complex conflict handling.  
- Requires schema migrations on app updates.

---

### Option C — Local Event Queue (Recommended)
App stores a **local queue of user actions/events** (start task, complete swap, log issue).  
Each event has a **UUID**, **timestamp**, and **hash** for idempotency and replay safety.  
Data required for UX (routes, tasks, maps) is cached separately.  
A **sync engine** replays queued events to the backend when online, then reconciles new server state.

**Pros**
- Lightweight; minimal local storage.  
- Predictable idempotent event flow.  
- Natural fit for MobilityCorp’s event-driven backend (Kafka topics).  
- Simplifies schema evolution (event contracts stable over time).  

**Cons**
- Requires robust conflict and retry handling.  
- Slightly more engineering upfront for the local event engine.  

---

### Option D — CRDT-based Data Replication
Use Conflict-Free Replicated Data Types (e.g., Automerge, Realm Sync) for eventual consistency.

**Pros**
- Elegant mathematical conflict resolution.  
- Ideal for true collaborative editing scenarios.  

**Cons**
- Overkill for operational workflows.  
- Higher compute and battery cost on mobile.  
- Harder to audit and replay deterministically.  

---

## Decision

Adopt **Option C – Local Event Queue with Server-Authoritative Reconciliation**.

- The **Field-Ops App** maintains a persistent, append-only queue of user actions (task status changes, notes, battery swap logs).  
- Each event is **idempotent**, **timestamped**, and carries a **local operation hash** to detect duplicates.  
- The **Mobile Sync Service** (middleware) processes queued events in order and returns updated state snapshots.  
- Conflicts are resolved by **server-wins + merge heuristics**:
  - If a task is already completed in server state → reject duplicate.  
  - If timestamps differ → keep newest; append audit record.  
- Local caches of routes/tasks are versioned via **ETags** or **revision numbers**.  
- On reconnect, app performs **3-phase sync**:  
  1. Push queued events.  
  2. Fetch updated routes/tasks.  
  3. Reconcile and notify user.  
- Sync retries use **exponential backoff** with power-aware scheduling.

---

## Consequences

**Positive**
- Reliable field operations even without connectivity.  
- Seamless sync across thousands of operatives.  
- Deterministic replay for audit and reconciliation.  
- Aligns with event-driven backend (Kafka topics).  

**Trade-offs**
- Slightly more client complexity (local store + sync queue).  
- Requires careful handling of merge conflicts and retries.  
- Additional testing for network edge cases and app restarts.  

---

## Implementation Details (High-level)

| Component | Responsibility | Notes |
|---|---|---|
| **Field-Ops App** | Local event queue, caching, offline UX | Uses SQLite/Realm; encrypt local store |
| **Sync Engine (client-side)** | Detect connectivity, trigger push/pull sync, exponential backoff | Background service; battery-aware |
| **Mobile Sync API (backend)** | Receives events, deduplicates, applies to canonical DB, returns updated state | Publishes successful events to Kafka |
| **Conflict Resolver** | Applies server-wins with audit logging | Logs discrepancies for BI & QA |
| **Audit Log** | Stores all event hashes and reconciliation outcomes | Immutable for compliance |
| **Notification Service** | Notifies app of new assignments or plan updates | WebSocket/push fallback to polling |

**Data Model Example**
```text
{
  "event_id": "uuid",
  "task_id": "task-1234",
  "user_id": "op-5678",
  "timestamp": "2025-10-18T09:30:00Z",
  "operation": "battery_swap_complete",
  "payload": {...},
  "hash": "sha256(event_id+payload)",
  "retries": 0
}

sequenceDiagram
    title Field-Ops App Offline/Online Sync Flow

    participant APP as Field-Ops App
    participant QUEUE as Local Event Queue
    participant SYNC as Mobile Sync Service
    participant API as Backend API
    participant BUS as Event Bus (Kafka)
    participant AUD as Audit Log

    %% Offline usage
    APP->>QUEUE: Record event {uuid, operation, payload}
    APP-->>APP: Display confirmation (local only)

    %% Connectivity restored
    APP->>SYNC: Detect online; start sync
    SYNC->>API: Push queued events (batch)
    API->>AUD: Log receipt + hashes
    API->>BUS: Publish event {ride.task.update}
    API-->>SYNC: Return updated tasks/routes
    SYNC->>QUEUE: Mark synced; purge confirmed
    SYNC-->>APP: Refresh local state (merged routes)
    APP-->>AUD: Append local reconciliation log

---

### Risks and Mitigations

| Risk                                         | Likelihood | Impact | Mitigation                                              |
| -------------------------------------------- | ---------: | -----: | ------------------------------------------------------- |
| Event loss or duplication                    |        Low |   High | UUID + hash; idempotent server processing; retries      |
| Clock skew causing mis-ordering              |        Med |    Med | Use server timestamp on commit; sync NTP periodically   |
| Storage exhaustion on device                 |    Low–Med |    Med | Compact queue; cap event retention (e.g., 30 days)      |
| Data corruption (app crash mid-sync)         |        Med |    Med | Write-ahead logging; transactional local DB             |
| Unauthorized local access                    |        Low |   High | Encrypt local DB; enforce app-level auth tokens         |
| Inconsistent server state after partial sync |        Med |    Med | Atomic server apply; rollback on failure                |
| User confusion post-sync                     |        Low |    Med | Clear in-app notifications of merges/conflicts          |
| Schema evolution / app version drift         |        Med |    Med | Versioned event contracts; backward compatibility layer |

---

### Alternatives Considered

* CRDT replication – rejected as unnecessary complexity for operational workflows.
* Web-first app – rejected due to offline requirements.
* Manual paper fallback – existing ops burden; replaced by digital queue.

### Links

* ADR-002 – External Dependency SLA & Retry Handling
* ADR-005 – Routing Solver (VRP-TW)
* ADR-006 – Alerts & Theft Detection Logic
* ADR-013 – Immutable Audit Log Architecture
* ADR-016 – AI Interchange Layer
* ADR-007 – Data Platform Architecture