---
id: "004"
title: Demand Prediction Model Design
status: proposed
date: 2025-10-18
---

## Context and Problem Statement

MobilityCorp’s new platform must **predict vehicle demand across hubs and regions** to optimise:

- **Fleet distribution and rebalancing** (routing, ADR-005)  
- **Pricing and promotion strategies** (ADR-002)  
- **Field operations scheduling** (battery swaps, recovery tasks)  
- **User experience personalisation / concierge service**  

The system must provide:
- Accurate short-term forecasts (hourly to 72 hours)  
- Medium-term projections (weekly/monthly) for planning  
- Explanations for each forecasted pattern (compliance + business trust)  
- Cost transparency and graceful fallback when data or models are unavailable  

Given MobilityCorp’s historical dataset (years of telemetry, weather, events, and operational logs), the platform can support **multi-model AI forecasting** rather than simple heuristics.

---

## Questions

- Which forecasting approach best balances **accuracy, interpretability, and compute cost**?  
- How do we combine different model types for optimal performance?  
- How do we integrate forecasts with downstream services (Routing, Pricing, Concierge)?  
- How do we meet GDPR and EU AI Act explainability requirements?  
- How do we prevent model drift or bias across cities and regions?  

---

## Options

### Option A — Heuristic / Rules-Only Baseline
Use moving averages, seasonal multipliers, and fixed weather coefficients.

"Fixed weather coefficients" are predetermined numerical values applied to weather variables (such as temperature or rainfall) to adjust demand predictions in a simple, transparent way. For example, a rule might state that demand increases by a fixed percentage for every 5°C drop in temperature, or decreases by a set amount when rainfall exceeds a threshold. These coefficients do not adapt automatically and must be manually set and tuned for each region.

**Pros**
- Transparent, robust, and cheap.
- Useful fallback when data or model unavailable.

**Cons**
- Cannot adapt to sudden events or complex seasonality.
- Manual tuning required per region.

---

### Option B — Classical ML / Time-Series Models
Per-hub or pooled models (e.g., **XGBoost**, **LightGBM**, **Prophet**, **SARIMAX**) using engineered features: historical demand, weather, calendar, and event data.

**Pros**
- Good balance between accuracy, interpretability, and cost.  
- Explainable via feature importance and SHAP values.  
- Easy to deploy in CPU-only environments.

**Cons**
- Requires feature engineering and tuning.  
- Limited performance for long-term or cross-hub dependencies.

---

### Option C — Deep Learning Forecasting (TFT, LSTM, N-BEATS)
Train deep models for city-wide, multi-horizon forecasting using temporal, exogenous, and spatial correlations.

This means using advanced deep learning models (like TFT, LSTM, or N-BEATS) to predict demand for the entire city over multiple future time periods (multi-horizon forecasting). These models learn from:
- Temporal correlations: Patterns over time (e.g., daily, weekly cycles, trends).
- Exogenous correlations: External factors that influence demand, such as weather, events, or holidays.
- Spatial correlations: Relationships between different locations or regions in the city (e.g., how demand in one area affects another).

By training on all these types of data, the models can make more accurate and nuanced forecasts for different times and places across the city.

**Pros**
- Learns complex temporal and spatial relationships.  
- Handles non-linear interactions and irregular events.  

**Cons**
- Higher compute and maintenance cost.  
- Harder to explain and validate under AI governance.  
- Needs GPU/accelerator infrastructure.

---

### Option D — Composite Forecasting Platform (**Recommended**)
Combine predictions from both classical machine learning models (such as XGBoost or Prophet) and deep learning models (such as LSTM or TFT) in a unified ensemble. Manage and serve these models through a standard Forecasting Service, which is integrated behind the AI Interchange Layer (ADR-0016) to ensure consistent governance, orchestration, and cost control for all AI services.

**Design characteristics:**
- Ensemble weighting by recent model accuracy per hub/region.  
- Predicts demand for each hub, hour, and vehicle type.  
- Includes contextual signals: weather, events, transit strikes, holidays.  
- Produces explainability metadata (feature importances + residuals).  
- Logs every forecast and version for audit and retraining.

**Pros**
- Leverages MobilityCorp’s historical data to reach high accuracy.  
- Combines interpretability and advanced pattern recognition.  
- Supports different horizons (operational vs strategic).  
- Enables downstream optimisation (routing, pricing).  

**Cons**
- Increased complexity in orchestration and governance.  
- Requires dedicated ML Ops pipeline and feature store.  
- Higher initial setup cost.

---

### Option E — Personalised Forecasts (Concierge Tier, Opt-In)
(Optional premium module)
Predicts individual user demand (e.g., “likely to rent a van on weekends”), used for personalised notifications or pre-positioning.

**Pros**
- Enhances user engagement and retention.  
- Can inform proactive fleet allocation near expected users.

**Cons**
- Must be **strictly opt-in** (GDPR).  
- Requires anonymised training and consent records.  

---

## Recommendation

Adopt **Option D: Composite Forecasting Platform** as the baseline service for MobilityCorp’s next-generation predictive infrastructure.

- Deploy a **Forecasting Service** that aggregates classical ML and deep-learning models into a composite prediction.  
- Integrate through the **AI Interchange Layer** to ensure consistent governance, cost tracking, and explainability.  
- Maintain **heuristics (Option A)** as deterministic fallback during outages or budget constraints.  
- Enable **Personalised Forecasting (Option E)** only in GDPR-compliant opt-in contexts.  
- All forecasts and explanations are stored in the **Data Platform (ADR-0007)** for retraining and audit.

---

## Consequences

**Positive**
- Uses existing historical data to deliver immediate ROI.  
- Provides explainable, multi-horizon forecasts supporting multiple business functions.  
- Creates a foundation for continuous learning and model governance.  
- Fully EU-hosted; no dependency on third-party SaaS.  

**Trade-offs**
- Higher implementation complexity (ensemble management, retraining cadence).  
- Requires strict cost and drift monitoring.  
- Needs coordination between Data, AI, and Ops teams.  

---

## Implementation Details (High-level)

| Component | Function | Notes |
|------------|-----------|-------|
| **Forecasting Service** | Hosts ensemble models; exposes `/predict`, `/explain`, `/metrics` APIs. | Centralised under AI Interchange. |
| **AI Interchange Layer** | Provides orchestration, cost tracking, and governance hooks. | Shared AI infra. Integrates with cost guardrails (ADR-018) to monitor and enforce budget limits for model inference and retraining. |
| **Feature Store (ADR-016)** | Stores and manages input features for training/inference, supports feature versioning and freshness validation. | Refreshed hourly from telemetry; schema validation and freshness checks performed before each forecast run. |
| **Data Platform (ADR-007)** | Manages pipelines, data lineage, and model logs. | Integration with IoT, weather, and event feeds. |
| **AI Cost & Budget Guardrails (ADR-018)** | Monitors and enforces cost limits for AI workloads. | Integrated with AI Interchange Layer to trigger fallback or alert when budget thresholds are reached. |
| **Retraining Cadence & Governance** | Ensures models remain accurate and compliant. | Automatic retraining triggered by drift detection, scheduled monthly retraining, and on major data schema changes. Governance audits performed quarterly. |
| **Routing Service (ADR-005)** | Consumes forecasts for route planning and pre-positioning. | Subscribes to forecast topics. |
| **Pricing Engine (ADR-002)** | Adjusts rates based on predicted demand. | Uses hourly or daily forecasts. |
| **Concierge/Personalisation** | Optional; provides user-level demand insight. | GDPR opt-in only. |

---

### Data Inputs

| Category | Examples | Source |
|-----------|-----------|--------|
| **Telemetry** | Rides started/ended, battery %, location | IoT feed |
| **Calendar** | Hour-of-day, day-of-week, holidays | Data Platform |
| **Weather** | Temperature, rainfall, wind | External API |
| **Events** | Metro strikes, concerts, festivals | Partner feeds |
| **Operational** | Hub capacity, maintenance backlog | Internal APIs |
| **User Opt-in (optional)** | Usage frequency, trip types | Consent-based data |

---

### Outputs


### Forecasting Service API Example

Sample `/predict` request:
```json
{
    "hub_id": "HUB-123",
    "vehicle_type": "van",
    "horizon_hours": 24,
    "context": {
        "weather": {"temperature": 18, "rainfall": 0.2},
        "events": ["metro_strike"],
        "operational": {"capacity": 50}
    }
}
```
Sample response:
```json
{
    "forecast": [
        {"hour": 1, "rides": 12, "confidence": 0.92},
        {"hour": 2, "rides": 15, "confidence": 0.90}
        // ...
    ],
    "feature_importance": {"weather.temperature": 0.3, "events.metro_strike": 0.5},
    "explanation": "Metro strike increases demand by 20%. Temperature has moderate effect.",
    "model_version": "2025.10.01"
}
```

---

## Sequence Flow

```mermaid
flowchart LR
    subgraph Ingestion
        IOT[IoT Telemetry]
        WEATH[Weather API]
        EVENTS[Events Feed]
        CAL[Calendar Data]
        OPS[Operational Data]
        FS[Feature Store]
    end

    subgraph Forecasting
        ML1[Classical ML Models (XGBoost, Prophet)]
        DL1[Deep Learning Models (TFT, LSTM)]
        ENS[Ensemble Weighting / Meta-Model]
        EXPL[Explainability Engine (SHAP, Feature Importance)]
    end

    subgraph Consumers
        ROUTE[Routing Service (ADR-005)]
        PRICE[Pricing Engine (ADR-002)]
        OPSDASH[Back Office / Ops Dashboard]
        CONC[Concierge / Personalised Layer]
    end

    IOT --> FS
    WEATH --> FS
    EVENTS --> FS
    CAL --> FS
    OPS --> FS
    FS --> ML1
    FS --> DL1
    ML1 --> ENS
    DL1 --> ENS
    ENS --> EXPL
    ENS --> ROUTE
    ENS --> PRICE
    ENS --> OPSDASH
    ENS --> CONC
    EXPL --> OPSDASH
    EXPL --> AIINT[AI Interchange & Audit Log]

---

### Risks and Mitigations

| Risk                                   | Likelihood | Impact | Mitigation                                               |
| -------------------------------------- | ---------- | ------ | -------------------------------------------------------- |
| Model drift                            | Med        | High   | Continuous monitoring, automatic retrain triggers.       |
| Data quality issues                    | Med        | Med    | Schema validation, feature freshness checks.             |
| AI cost overruns                       | Low–Med    | Med    | Cost guardrails via AI Interchange (ADR-018).           |
| Explainability gaps                    | Low        | High   | SHAP-based feature reporting; regulator dashboards.      |
| Forecast bias                          | Med        | High   | Fairness audits per region; balanced sampling.           |
| External data latency (weather/events) | Med        | Med    | Caching and asynchronous updates.                        |
| Data privacy (personal forecasts)      | Low        | High   | GDPR-compliant consent management; aggregation fallback. |


---

### Alternatives Considered

* Single-model strategy — rejected; reduces flexibility and explainability.
* Third-party forecasting SaaS — rejected due to GDPR, lock-in, and cost.
* Deep-only approach — deferred; adds complexity without strong ROI.

---

### Links

* ADR-005 – Routing Solver
* ADR-002 – Pricing & Billing Microservice Architecture
* ADR-014 – AI Interchange Layer
* ADR-016 – Feature Store
* ADR-017 – AI Governance & Explainability
* ADR-018 – AI Cost & Budget Guardrails
* ADR-007 – Data Platform Architecture