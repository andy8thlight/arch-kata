---
id: "0005"
title: Routing Solver (VRP-TW)
status: proposed
date: 2025-10-21
---

## Context and Problem Statement

MobilityCorp requires an intelligent **Routing Solver** capable of optimising fleet dispatch and scheduling under real-world constraints, specifically the **Vehicle Routing Problem with Time Windows (VRP-TW)**.

The system must:

- Minimise total distance, travel time, and fuel/energy consumption.  
- Respect time windows, vehicle capacity, and driver shift limits.  
- React dynamically to changing conditions (traffic, cancellations, new requests).  
- Integrate seamlessly with the event-driven data platform (ADR-007).  
- Provide auditability and explainability for operational decisions.

The challenge is to design a solver architecture that balances optimisation accuracy, response latency, and scalability while leveraging shared data and infrastructure.

---

## Questions

- Should optimisation run centrally or in a distributed / edge configuration?  
- How frequently should routes be recalculated (batch vs continuous)?  
- Which solver framework or engine provides the right trade-off between performance and maintainability?  
- How should real-time telemetry updates (Kafka events) feed incremental re-optimisation?  
- Can historical routing patterns be reused for context or learning (Vector DB embeddings)?  

---

## Options

### Option A — Static Batch Solver
Run nightly route optimisations using historical demand data and fixed time windows.

**Pros**
- Simple; deterministic output.  
- Minimal infrastructure complexity.

**Cons**
- Stale results; cannot adapt to real-time conditions.  
- Inefficient for dynamic field operations.

---

### Option B — Continuous Real-Time Solver (Monolithic)
Single service consuming live events and recalculating routes continuously.

**Pros**
- Always up-to-date routes.  
- Straightforward integration with event bus.

**Cons**
- High compute load and cost.  
- Hard to scale; complex concurrency and locking.

---

### Option C — Hybrid Solver Architecture (Recommended)
Use a **distributed optimisation service** combining batch pre-planning and real-time incremental adjustments.  
Leverage the shared **event-driven data platform (ADR-007)** for inputs and outputs.

- **Kafka** ingests trip requests, telemetry, and state updates.  
- **Databricks / Feature Store** provides aggregated demand patterns and model features.  
- **Routing Solver Service** performs dynamic optimisation (VRP-TW).  
- **Optional Vector Database** enables retrieval of similar historical routes for contextual adjustments or explainability.  

**Pros**
- Balances compute efficiency and responsiveness.  
- Naturally integrates with existing data platform and AI infrastructure.  
- Supports future contextual enhancements via vector retrieval.  

**Cons**
- Requires orchestration between batch and streaming pipelines.  
- Slightly more complex deployment and monitoring.  

---

## Recommendation

Adopt **Option C – Hybrid Solver Architecture** using event-driven ingestion and feature-enhanced optimisation.

- Run periodic **batch pre-plans** (e.g., every hour) using aggregated demand data from Databricks.  
- Apply **incremental updates** on top of pre-plans when new events arrive via Kafka.  
- Maintain **solver state** and **route versions** in the canonical datastore.  
- Expose results through an **Optimisation API** consumed by dispatch, mobile, and analytics systems.  
- Optionally use **Vector DB lookups** for route similarity or explainability (e.g., “retrieve routes that succeeded under similar conditions”).

---

## Consequences

**Positive**
- Scalable, adaptive routing aligned with MobilityCorp’s event-driven ecosystem.  
- Provides a path toward explainable and context-aware optimisation.  
- Reduces redundant computation and improves fleet utilisation.

**Trade-offs**
- Increased orchestration complexity (batch + streaming).  
- Requires careful solver tuning and state synchronisation.  
- Additional monitoring and rollback mechanisms for failed updates.

---

## Implementation Details (High-level)

| Component | Responsibility | Notes |
|---|---|---|
| **Kafka / Event Bus** | Stream trip requests, telemetry, and route feedback | Shared ingestion layer (ADR-007) |
| **Databricks Lakehouse** | Aggregate demand, store historical routes, train predictive features | EU-resident; supports model retraining |
| **Feature Store** | Provide solver inputs (ETA models, vehicle constraints) | Common data source for AI & optimisation |
| **Routing Solver Service** | Compute VRP-TW solutions; apply incremental updates | Exposed via internal API |
| **Vector Database (optional)** | Store route embeddings for similarity / explainability | Reuses embedding pipeline from ADR-009 |
| **Audit Log** | Record optimisation decisions, inputs, and versions | Immutable; supports SLA traceability |
| **Dispatch / Field-Ops Apps** | Consume optimised routes, report outcomes | Feedback loop via Kafka events |

**Sequence Example**
```mermaid
sequenceDiagram
    title Hybrid Routing Solver (VRP-TW) Flow

    participant APP as Dispatch / Field-Ops App
    participant KAF as Kafka (Event Bus)
    participant DWH as Databricks (Lakehouse)
    participant FS as Feature Store
    participant SOLV as Routing Solver Service
    participant VDB as Vector DB (Optional)
    participant AUD as Audit Log

    APP->>KAF: Emit trip requests / status updates
    KAF-->>DWH: Stream to warehouse
    DWH-->>FS: Generate features for solver input
    FS-->>SOLV: Provide demand & constraints
    Note over SOLV,VDB: Optional route similarity lookup
    SOLV->>VDB: Query similar historical routes
    VDB-->>SOLV: Return context embeddings
    SOLV-->>APP: Return optimised routes (VRP-TW)
    SOLV->>AUD: Log optimisation run and decision
    APP->>KAF: Publish feedback / route outcomes

---

## Risks and Mitigations

| Risk                                       | Likelihood | Impact | Mitigation                                          |
| ------------------------------------------ | ---------: | -----: | --------------------------------------------------- |
| Solver latency under heavy load            |        Med |   High | Scale horizontally; pre-batch compute windows       |
| Inconsistent state across solver instances |        Med |   High | Use distributed locking and central version control |
| Model drift reducing optimisation quality  |        Med |    Med | Periodic retraining and feature refresh             |
| Kafka event loss or duplication            |        Low |    Med | Enable acknowledgements and idempotent consumers    |
| Route recommendation bias                  |        Low |    Med | Log explanations; use diverse training data         |
| Cost of optional vector retrieval          |        Low |    Low | Enable only for contextual scenarios                |


---

## Alternatives Considered

* Static batch solver – rejected due to latency and inefficiency.
* Continuous monolithic solver – rejected for scalability limitations.
* Hybrid event-driven solver – chosen for adaptability, integration with ADR-007, and extensibility for contextual AI (ADR-009).

## Links

* ADR-002 – External Dependency SLA & Retry Handling
* ADR-007 – Data Platform Architecture
* ADR-008 – Mobile Offline Sync Strategy
* ADR-009 – Personalisation / Concierge Service Architecture
* ADR-013 – Immutable Audit Log Architecture
* ADR-016 – AI Interchange Layer