---
id: "007"
title: Data Platform Architecture
status: proposed
date: 2025-10-22
---

## Context and Problem Statement

MobilityCorp operates across multiple European countries and relies on a steady stream of **telemetry, routing, weather, and transport data** to drive AI services such as **routing (ADR-005)**, **demand prediction (ADR-004)**, and **concierge personalisation (ADR-009)**.  

Earlier prototypes used a **UK-centric (TfL)** feed model and static CSV ingest.  
To scale and maintain compliance, MobilityCorp requires a **region-agnostic, event-driven data platform** that unifies diverse feeds into a single, EU-resident analytical and operational backbone.

---

## Questions

- How can regional mobility data (e.g., RATP, BVG, ATAC) be standardised into one schema?  
- How should we incorporate weather and environmental context into real-time pipelines?  
- What governance mechanisms ensure schema evolution and data lineage across regions?  
- How do AI models consume these streams reliably and reproducibly?  
- How do we balance cost, latency, and audit requirements?

---

## Options

### Option A — Central Batch ETL
Nightly jobs pull raw data from all sources into a warehouse.

**Pros**
- Simple to implement.  
**Cons**
- High latency, no real-time response, limited lineage and schema governance.

---

### Option B — Event-Driven Lakehouse Architecture (Recommended)
Use **Kafka** for streaming ingestion and **Databricks Delta Lake** for unified batch and stream processing.

**Pros**
- Real-time, region-aware data availability.  
- Natural fit for MobilityCorp’s AI and routing workloads.  
- Schema evolution and audit support via Delta metadata.  
**Cons**
- Increased operational complexity.  
- Requires strict schema governance and topic management.

---

## Recommendation

Adopt **Option B – Event-Driven Lakehouse Architecture** with region and weather enrichment.

**Key design decisions**
1. **Kafka Event Bus:** backbone for ingesting telemetry, transport, weather, and demand events.  
2. **Transport Adapter Service:** plug-in connectors per country normalising GTFS-RT or proprietary feeds into `transport.status` events.  
3. **Weather Collector:** integrates external weather APIs; publishes `weather.conditions` to Kafka.  
4. **Databricks Structured Streaming:** cleans, joins, and enriches events into Delta tables.  
5. **Data Residency:** all clusters, Kafka topics, and Delta storage remain within the EU.  
6. **Schema Registry:** all topics version-controlled with compatibility checks.  
7. **Downstream Consumers:**  
   - Feature Store (ADR-016)  
   - Routing Solver (ADR-005)  
   - Demand Prediction (ADR-004)  
   - Concierge Service (ADR-009)  
8. **Audit & Observability:** ingestion lineage logged to **ADR-011**; metrics published to **ADR-013**.

---

## Consequences

**Positive**
- Region-aware, real-time pipelines.  
- Unified transport and weather context for AI workloads.  
- Strong data lineage and EU compliance.  

**Trade-offs**
- More infrastructure and governance overhead.  
- Higher complexity in multi-region schema versioning.

---

## Implementation Details (High-level)

| Component | Responsibility | Notes |
|---|---|---|
| **Kafka (EU Cluster)** | Event backbone for all real-time feeds | Confluent/MSK EU region |
| **Transport Adapter Layer** | Connect to local transport APIs, normalise schema | Emits `transport.status` |
| **Weather Collector** | Pull weather data periodically from external APIs | Emits `weather.conditions` |
| **Databricks Pipelines** | Transform, join, and enrich streams | Writes curated Delta tables |
| **Schema Registry** | Manage topic contracts and evolution | Enforced in CI/CD |
| **Audit Log (ADR-011)** | Record pipeline and schema events | Tamper-evident ledger |
| **Observability (ADR-013)** | Monitor latency, volume, and errors | Unified OTel metrics |
| **Feature Store (ADR-016)** | Consume enriched data for AI training/inference | Feeds downstream models |
| **Routing Solver (ADR-005)** | Subscribe to enriched transport/weather events | Context for route optimisation |

**Sequence Example**

<img width="3554" height="978" alt="007" src="https://github.com/user-attachments/assets/ce8034d8-dff4-433a-83fc-356850eaeb98" />

---

## Risks and Mitigations

| Risk                      | Likelihood | Impact | Mitigation                            |
| ------------------------- | ---------: | -----: | ------------------------------------- |
| Provider API schema drift |        Med |   High | Schema registry & contract tests      |
| Weather API downtime      |        Low |    Med | Caching, retry logic                  |
| Cross-region latency      |        Med |    Med | Regional ingestion nodes              |
| High data volume costs    |        Med |    Med | Tiered retention and aggregation      |
| Regulatory non-compliance |        Low |   High | EU region enforcement and audit hooks |

---

## Alternatives Considered

* Batch ETL only – rejected for lack of timeliness.
* Event-driven ingestion – chosen for scalability, governance, and real-time analytics alignment.

## Links

* ADR-004 – Demand Prediction Model
* ADR-005 – Routing Solver (VRP-TW)
* ADR-009 – Concierge / Personalisation Service Architecture
* ADR-011 – Immutable Audit Log Architecture
* ADR-013 – Observability & Metrics Standardisation
* ADR-016 – AI Data Pipeline & Feature Store Design

